# Codex LLM UI

Тестовое задание, описнаие которого можно найти здесь: https://codex.so/llm-ui

# Архитектура проекта

## Backend

Реализован на express.js, является прокси-звеном между ui и внешним LLM.

На данный момент имеет следующие эндпоинты: 

- `/health` - health-check
- `/chat/generate` - запрос к llm 

### Команды

Запуск приложения:

```shell
npm run dev:backend
```

Запуск тестов:

```shell
npm run test:backend
```

Пример запроса:

```shell
 curl -X POST http://localhost:3000/chat/generate \
      -H "Content-Type: application/json" \
      -d '{"message":"Hello World"}'
```

## Frontend

Реализован при помощи svelte. 

Является жалкой пародией на UI, представленный в макете.

Запуск приложения:

```shell
npm run dev:frontend
```

Запуск тестов:

```
¯\_(ツ)_/¯
```

###

# Checklist

- [x] - инициализировать базовую структуру проекта

**Backend:**

- [x] - реализовать минимально рабочую версию
- [x] - реализовать возможность кидать запросы LLM с единоразоваой обработкой ответа
- [ ] - реализовать потоковую обработку ответа LLM при помощи SSE

**Frontend:**

- [x] - реализовать минимально рабочую версию UI
- [x] - реализовать возможность отправлять запросы LLM чеез backend API
- [x] - реализовать форму для ведения диалога с LLM
- [x] - реализовать парсинг ответов в markdown для более качественного отображения 
- [ ] - реализовать поддержку потоковой обработки ответа через SSE
- [ ] - реализовать разделение блока ответа на размышление и ответ
- [ ] - привести стилизацию к требуемому виду

# LLM Chat Interface - Environment Configuration

# Server Configuration
PORT=3000

# LLM Service Configuration
LLM_API_URL=https://api.example.com/v1/chat
LLM_API_TOKEN=your-llm-api-token-here

# CORS Configuration (comma-separated list of allowed origins)
CORS_ORIGINS=http://localhost:5173,http://localhost:4173
